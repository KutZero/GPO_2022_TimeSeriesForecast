<!DOCTYPE html>
<html>
    <head>
      <title>LSTM</title>
      <link rel="stylesheet" href="../css/style.css" type="text/css"/>
    </head>
    <body>
      <h1>LSTM - сети долгой краткосрочной памяти</h1>
      <p style="font-size: 18px">
        Для задач в предсказании и классификации событий на временном ряду,
        считается классическим решением применение рекуррентных нейронных
        сетей. Но у обычных рекуррентных нейронных сетей может наблюдаться
        проблема долгосрочной памяти: вне зависимости оттого, насколько важна
        была информация, её вес в процессе большого количества итераций может
        сильно уменьшится, или она вовсе может пропасть.
      </p>
      <p style="font-size: 18px">
        Для решения данной проблемы в 1997 году Зеппом Хохрайтер и
        Юргеном Шмидхубером была предложена долгая краткосрочная память (Long
        short-term memory; LSTM) – особая разновидность архитектуры рекуррентных
        нейронных сетей, способная к обучению долговременным зависимостям.
      </p>
      <p style="font-size: 18px">
        LSTM разработаны специально, чтобы избежать проблемы
        долговременной зависимости. Запоминание информации на долгие периоды
        времени – это их обычное поведение. Ключевой компонент LSTM – это
        состояние ячейки – горизонтальная линия, проходящая по верхней части
        схемы. Состояние ячейки напоминает конвейерную ленту. Она проходит
        напрямую через всю цепочку, участвуя лишь в нескольких линейных
        преобразованиях. Информация может легко течь по ней, не подвергаясь
        изменениям. Тем не менее, LSTM может удалять информацию из состояния
        ячейки; этот процесс регулируется структурами, называемыми фильтрами.
        Фильтры позволяют пропускать информацию на основании некоторых
        условий. Они состоят из слоя сигмоидальной нейронной сети и операции
        поточечного умножения.
      </p>

      <h2>Схема LSTM</h2>
      <img src="../images/LSTM.png">
      <p style="font-size: 18px">
        Во-первых, по «трубам» этой схемы текут вектора. Входное слово X(t) в синем кружочке —
        в виде вектора, в стрелочках — вектор, все операции — с векторами.
        В желтых кирпичах — слой нейросети. Напомним: это значит, что там спрятаны
        три операции: сначала входной вектор умножается на матрицу весов слоя (которую
        нейросеть вырабатывает в ходе тренировки), к произведению прибавляется сдвиг (bias),
        наконец, вектор-сумма поэлементно проходит через функцию активации нейронов: сигмоиду
        или гиперболический тангенс. Их графики вы видели выше.
        Посимвольная операция означает, что что каждый элемент вектора по отдельности терпит
        какие-то изменения (как с функцией tanh), а «склеивание» из векторов [1, 2] и
        [3, 4] дает один вектор [1, 2, 3, 4].
      </p>

      <form action="Data_about_model_window.html">
        <button class="button">Вернуться на страницу с моделями</button>
      </form>
    </body>
</html>
