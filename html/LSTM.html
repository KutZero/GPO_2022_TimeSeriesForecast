<!DOCTYPE html>
<html>
    <head>
      <title>LSTM</title>
      <link rel="stylesheet" href="../css/style.css" type="text/css"/>
    </head>
    <body>
<<<<<<< HEAD
      <h1>LSTM - сети долгой краткосрочной памяти</h1>
      <p>
        Для задач в предсказании и классификации событий на временном ряду,
        считается классическим решением применение рекуррентных нейронных
        сетей. Но у обычных рекуррентных нейронных сетей может наблюдаться
        проблема долгосрочной памяти: вне зависимости оттого, насколько важна
        была информация, её вес в процессе большого количества итераций может
        сильно уменьшится, или она вовсе может пропасть.
      </p>
      <p>
        Для решения данной проблемы в 1997 году Зеппом Хохрайтер и
        Юргеном Шмидхубером была предложена долгая краткосрочная память (Long
        short-term memory; LSTM) – особая разновидность архитектуры рекуррентных
        нейронных сетей, способная к обучению долговременным зависимостям.
      </p>
      <p>
        LSTM разработаны специально, чтобы избежать проблемы
        долговременной зависимости. Запоминание информации на долгие периоды
        времени – это их обычное поведение. Ключевой компонент LSTM – это
        состояние ячейки – горизонтальная линия, проходящая по верхней части
        схемы. Состояние ячейки напоминает конвейерную ленту. Она проходит
        напрямую через всю цепочку, участвуя лишь в нескольких линейных
        преобразованиях. Информация может легко течь по ней, не подвергаясь
        изменениям. Тем не менее, LSTM может удалять информацию из состояния
        ячейки; этот процесс регулируется структурами, называемыми фильтрами.
        Фильтры позволяют пропускать информацию на основании некоторых
        условий. Они состоят из слоя сигмоидальной нейронной сети и операции
        поточечного умножения.
      </p>

      <h2>Схема LSTM</h2>
      <img src="LSTM.png">
      <p>
        Во-первых, по «трубам» этой схемы текут вектора. Входное слово X(t) в синем кружочке —
        в виде вектора, в стрелочках — вектор, все операции — с векторами.
        В желтых кирпичах — слой нейросети. Напомним: это значит, что там спрятаны
        три операции: сначала входной вектор умножается на матрицу весов слоя (которую
        нейросеть вырабатывает в ходе тренировки), к произведению прибавляется сдвиг (bias),
        наконец, вектор-сумма поэлементно проходит через функцию активации нейронов: сигмоиду
        или гиперболический тангенс. Их графики вы видели выше.
        Посимвольная операция означает, что что каждый элемент вектора по отдельности терпит
        какие-то изменения (как с функцией tanh), а «склеивание» из векторов [1, 2] и
        [3, 4] дает один вектор [1, 2, 3, 4].
      </p>

      <a style="font-size: 120%; font-family: Verdana;"
       href="Data_about_model_window.html" class="button">Вернуться на страницу с моделями</a>
=======
        <h1>LSTM - сети долгой краткосрочной памяти</h1>
        <p>
            Для задач в предсказании и классификации событий на временном ряду,
считается классическим решением применение рекуррентных нейронных
сетей. Но у обычных рекуррентных нейронных сетей может наблюдаться
проблема долгосрочной памяти: вне зависимости оттого, насколько важна
была информация, её вес в процессе большого количества итераций может
сильно уменьшится, или она вовсе может пропасть. </p>
<p>
Для решения данной проблемы в 1997 году Зеппом Хохрайтер и
Юргеном Шмидхубером была предложена долгая краткосрочная память (Long
short-term memory; LSTM) – особая разновидность архитектуры рекуррентных
нейронных сетей, способная к обучению долговременным зависимостям. </p>
<p>
LSTM разработаны специально, чтобы избежать проблемы
долговременной зависимости. Запоминание информации на долгие периоды
времени – это их обычное поведение. Ключевой компонент LSTM – это
состояние ячейки – горизонтальная линия, проходящая по верхней части
схемы. Состояние ячейки напоминает конвейерную ленту. Она проходит
напрямую через всю цепочку, участвуя лишь в нескольких линейных
преобразованиях. Информация может легко течь по ней, не подвергаясь
изменениям. Тем не менее, LSTM может удалять информацию из состояния
ячейки; этот процесс регулируется структурами, называемыми фильтрами.
Фильтры позволяют пропускать информацию на основании некоторых
условий. Они состоят из слоя сигмоидальной нейронной сети и операции
поточечного умножения.
        </p>
        <h2>Схема LSTM</h2>
        <img src="../Images/LSTM.png">
        <p>
            Во-первых, по «трубам» этой схемы текут вектора. Входное слово X(t) в синем кружочке — в виде вектора, в стрелочках — вектор, все операции — с векторами.
В желтых кирпичах — слой нейросети. Напомним: это значит, что там спрятаны три операции: сначала входной вектор умножается на матрицу весов слоя (которую нейросеть вырабатывает в ходе тренировки), к произведению прибавляется сдвиг (bias), наконец, вектор-сумма поэлементно проходит через функцию активации нейронов: сигмоиду или гиперболический тангенс. Их графики вы видели выше.
Посимвольная операция означает, что что каждый элемент вектора по отдельности терпит какие-то изменения (как с функцией tanh), а «склеивание» из векторов [1, 2] и [3, 4] дает один вектор [1, 2, 3, 4].
        </p>
        <link rel="stylesheet" href="../css/button.css">
            <a style="font-size: 120%; font-family: Verdana;" href="Data_about_model_window.html" class="button">Вернуться на страницу с моделями</a>
>>>>>>> b9f1696c7a4df72f33f6a77427d75caf8f2f5ac6
    </body>
</html>
