{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.486552Z",
     "start_time": "2023-04-14T09:31:59.155387Z"
    },
    "cell_style": "center",
    "id": "p6xN-IEhhbla"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import ticker\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Reshape, Input, Dense, Flatten, Conv2D, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, concatenate, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Константы для путей к файлам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.502461Z",
     "start_time": "2023-04-14T09:32:06.486552Z"
    },
    "id": "bZHiwO4ShhEF"
   },
   "outputs": [],
   "source": [
    "# Пути к обработанным данным\n",
    "# Пути к X части выборки с массивами в каждой ячейке\n",
    "path_to_array_like_X_data = ('data\\\\Prepared data\\\\Run1\\\\X_data_array_like.xlsx',\n",
    "                             'data\\\\Prepared data\\\\Run2\\\\X_data_array_like.xlsx')\n",
    "# Пути к Y части выборки\n",
    "path_to_Y_data = ('data\\\\Prepared data\\\\Run1\\\\Y_data(binary_classification).xlsx', \n",
    "                  'data\\\\Prepared data\\\\Run2\\\\Y_data(binary_classification).xlsx') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Константы для обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.533973Z",
     "start_time": "2023-04-14T09:32:06.508457Z"
    }
   },
   "outputs": [],
   "source": [
    "PREP_image_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.549972Z",
     "start_time": "2023-04-14T09:32:06.538977Z"
    },
    "cell_style": "center",
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.565960Z",
     "start_time": "2023-04-14T09:32:06.552967Z"
    },
    "cell_style": "center",
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def to_list_of_64_values(x):\n",
    "  # делим начальную строку на пары чисел\n",
    "  # пары чисел тут - это просто строки\n",
    "  x = str(x[1:-1]).split(',')\n",
    "  x = np.array(x)\n",
    "\n",
    "  x = x.astype(float)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.581949Z",
     "start_time": "2023-04-14T09:32:06.569957Z"
    },
    "cell_style": "center",
    "deletable": false,
    "editable": false,
    "id": "HfWyHYJqhlBX"
   },
   "outputs": [],
   "source": [
    "# прочесть файл X_data_array-like.xlsx\n",
    "def get_array_like_X_df(path: str):\n",
    "    df = pd.read_excel(path,index_col=[0])\n",
    "    df = df.apply(lambda x: \n",
    "                  x.apply(to_list_of_64_values, convert_dtype=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.597939Z",
     "start_time": "2023-04-14T09:32:06.585947Z"
    },
    "cell_style": "center",
    "deletable": false,
    "editable": false,
    "id": "UH4wq7FOhlI1"
   },
   "outputs": [],
   "source": [
    "# прочесть файл Y_data(binary_classification).xlsx\n",
    "def get_Y_df(path: str):\n",
    "    df = pd.read_excel(path,index_col=[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.613929Z",
     "start_time": "2023-04-14T09:32:06.601938Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# кропы массива pandas имеют размер (PREP_image_size, PREP_image_size)\n",
    "# после преобразования в numpy через to_numpy() размер тот-же,\n",
    "# при том, что в каждой ячейке хранится массив из 64 чисел как объект\n",
    "# для работы нужно преобразовать кроп к размеру (PREP_image_size, PREP_image_size, 64)\n",
    "# чтобы каждый элемент массива был не объектом, а вещественным числом\n",
    "def pandas_crop_to_image_like_numpy(df):\n",
    "    x = df.to_numpy()\n",
    "    return np.stack([np.stack([x[i,j] for i in range(x.shape[0])],axis=0) for j in range(x.shape[1])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.645910Z",
     "start_time": "2023-04-14T09:32:06.617929Z"
    }
   },
   "outputs": [],
   "source": [
    "# приведение к виду, который принимают на вход слои Conv2D\n",
    "# (batch, channels, rows, cols) если data_format='channels_first'\n",
    "# (batch, rows, cols, channels) если data_format='channels_last'\n",
    "# тут выбран последний формат \n",
    "# а так как \"изображения\" состоят из 64 измерений, то \n",
    "# каналов либо 64, либо по 32\n",
    "def reshape_X_df_to_image_like_numpy(df, crop_size):\n",
    "    #rows_count = df.shape[0] - df.shape[0] % PREP_image_size\n",
    "    #cols_count = df.shape[1] - df.shape[1] % PREP_image_size\n",
    "    \n",
    "    print('||||||||||||||||||')\n",
    "    print('X df reshaping to 4D')\n",
    "    print('Original df size: ', df.shape)\n",
    "    print('Crop windows height/width: ', crop_size)\n",
    "    #print('New df size (если одна из размерностей не делится нацело на размер окна crop): ', (rows_count,cols_count))\n",
    "    \n",
    "    # тестовое. Обработка одного столбца датафрейма\n",
    "    '''temp = np.stack(\n",
    "        [pandas_crop_to_image_like_numpy(\n",
    "            df.iloc[i:i+PREP_image_size,0:PREP_image_size]) \n",
    "             for i in range(0,rows_count,PREP_image_size)]\n",
    "                ,axis=0)'''\n",
    "    \n",
    "    temp = np.concatenate([np.stack(\n",
    "        [pandas_crop_to_image_like_numpy(\n",
    "            df.iloc[i:i+crop_size,j:j+crop_size]) \n",
    "             for i in range(0,df.shape[0],crop_size)]\n",
    "                , axis=0) for j in range(0,df.shape[1],crop_size)]\n",
    "                    , axis=0)\n",
    "    \n",
    "    # поделим x выборку на значения времен и амплитуд\n",
    "    X_time = temp[:,:,:,:32]\n",
    "    X_amp = temp[:,:,:,32:]\n",
    "    \n",
    "    print('New X_time shape: ', X_time.shape)\n",
    "    print('New X_amp shape: ', X_amp.shape)\n",
    "    print('||||||||||||||||||\\n')\n",
    "    \n",
    "    return (X_time,X_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.677890Z",
     "start_time": "2023-04-14T09:32:06.653906Z"
    }
   },
   "outputs": [],
   "source": [
    "# приведение к нужному виду бинарных масок\n",
    "def reshape_Y_df_to_image_like_numpy(df, crop_size):\n",
    "    #rows_count = df.shape[0] - df.shape[0] % PREP_image_size\n",
    "    #cols_count = df.shape[1] - df.shape[1] % PREP_image_size\n",
    "    \n",
    "    print('||||||||||||||||||')\n",
    "    print('Y df reshaping to 3D')\n",
    "    print('Original df size: ', df.shape)\n",
    "    print('Crop windows height/width: ', crop_size)\n",
    "    #print('New df size (если одна из размерностей\\n не делится нацело на размер окна crop): ', (rows_count,cols_count))\n",
    "    \n",
    "    \n",
    "    Y_res = np.concatenate([np.stack(\n",
    "        [df.iloc[i:i+crop_size,j:j+crop_size].to_numpy().astype('float32') \n",
    "             for i in range(0,df.shape[0],crop_size)]\n",
    "                , axis=0) for j in range(0,df.shape[1],crop_size)]\n",
    "                    , axis=0)\n",
    "    \n",
    "    \n",
    "    Y_res = np.expand_dims(Y_res,axis=3)\n",
    "    \n",
    "    print('New numpy shape: ', Y_res.shape)\n",
    "    print('||||||||||||||||||\\n')\n",
    "    \n",
    "    return Y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.693880Z",
     "start_time": "2023-04-14T09:32:06.680890Z"
    }
   },
   "outputs": [],
   "source": [
    "# преобразовать массив кропов numpy Y выборки размера (batch,rows,cols) \n",
    "# в матрицу размера (rows,cols)\n",
    "def reshape_3D_Y_numpy_to_2D(arr, rows_count, cols_count):\n",
    "    \n",
    "    print('||||||||||||||||||')\n",
    "    print('Y arr reshaping to 2D')\n",
    "    print('Original arr size: ', arr.shape)\n",
    "    print('Crop windows height/width: ', PREP_image_size)\n",
    "    \n",
    "    crops_per_rows_count = int(rows_count/PREP_image_size) # кол-во строк / размер кропа\n",
    "    crops_per_cols_count = int(cols_count/PREP_image_size) # кол-во столбцов / размер кропа\n",
    "    \n",
    "    temp  = np.concatenate([\n",
    "                np.concatenate([arr[i + (j*crops_per_rows_count)] \n",
    "                             for i in range(crops_per_rows_count)],axis=0)\n",
    "                                 for j in range(crops_per_cols_count)],axis=1)\n",
    "    \n",
    "    print('New numpy shape: ', temp.shape)\n",
    "    print('||||||||||||||||||\\n')\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.725860Z",
     "start_time": "2023-04-14T09:32:06.698877Z"
    }
   },
   "outputs": [],
   "source": [
    "# вернет бинарную 1D маску, где 1 - для кропов с дефектами\n",
    "# 0 - для кропов без дефектов\n",
    "def calculate_crops_with_defects_positions(Y_arr, crop_size):\n",
    "    \n",
    "    print('||||||||||||||||||')\n",
    "    print('Defects nums calculating')\n",
    "    # Найдем на каких картинках есть дефекты\n",
    "    defects_nums = list()\n",
    "    for i in range(Y_arr.shape[0]):\n",
    "        if np.sum(Y_arr[i] > 0) >= 1:\n",
    "            defects_nums.append(True)\n",
    "        else:\n",
    "            defects_nums.append(False)\n",
    "\n",
    "    defects_nums = np.array(defects_nums, dtype='bool')\n",
    "\n",
    "    print(f'Для карт высотой и шириной в {crop_size}',\n",
    "          f'и общим кличеством: {Y_arr.shape[0]}',\n",
    "            f'дефекты присутствуеют на {np.sum(defects_nums)} картах',\n",
    "              sep='\\n')\n",
    "    print('||||||||||||||||||\\n')\n",
    "    \n",
    "    return defects_nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.757841Z",
     "start_time": "2023-04-14T09:32:06.730860Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X_time_arr, X_amp_arr, Y_arr, crop_size, X_time_max=0, X_amp_max=0):\n",
    "    # стндартизуем данные\n",
    "    # удалим кропы, в которых нет дефектов\n",
    "    \n",
    "    print('||||||||||||||||||')\n",
    "    print('Data preprocessing')\n",
    "    \n",
    "    print('Orig X_time_arr shape: ', X_time_arr.shape)\n",
    "    print('Orig X_amp_arr shape: ', X_amp_arr.shape)\n",
    "    print('Orig Y_arr shape: ', Y_arr.shape)\n",
    "    \n",
    "    \n",
    "    print('||||||||||||||||||')\n",
    "    print('Data standartization')\n",
    "    \n",
    "    # стандартизуем данные\n",
    "    if ((X_time_max == 0) and (X_amp_max == 0)):\n",
    "        X_time_max = X_time_arr.max()\n",
    "        X_amp_max = X_amp_arr.max()\n",
    "\n",
    "    print(f'X_time_max: {X_time_max}')\n",
    "    print(f'X_amp_max: {X_amp_max}')\n",
    "\n",
    "    X_time_arr = X_time_arr / X_time_max\n",
    "    X_amp_arr = X_amp_arr / X_amp_max\n",
    "    \n",
    "    print(f'X_time_max after standartization: {X_time_arr.max()}')\n",
    "    print(f'X_time_min after standartization: {X_time_arr.min()}')\n",
    "    \n",
    "    print(f'X_amp_max after standartization: {X_amp_arr.max()}')\n",
    "    print(f'X_amp_min after standartization: {X_amp_arr.min()}')\n",
    "    \n",
    "    print('||||||||||||||||||\\n')\n",
    "    \n",
    "    print('||||||||||||||||||')\n",
    "    print('Data with and witout defects splitting')\n",
    "    \n",
    "    # удалим кропы не содержищие дефекты\n",
    "    defects_nums = calculate_crops_with_defects_positions(Y_arr, crop_size)\n",
    "    \n",
    "    X_time_arr_def = X_time_arr[defects_nums]\n",
    "    X_amp_arr_def = X_amp_arr[defects_nums]\n",
    "    Y_arr_def = Y_arr[defects_nums]\n",
    "    \n",
    "    X_time_arr_non_def = X_time_arr[~defects_nums]\n",
    "    X_amp_arr_non_def = X_amp_arr[~defects_nums]\n",
    "    Y_arr_non_def = Y_arr[~defects_nums]\n",
    "    \n",
    "    print('X_time_arr_def shape: ', X_time_arr_def.shape)\n",
    "    print('X_time_arr_non_def shape: ', X_time_arr_non_def.shape)\n",
    "    \n",
    "    print('X_amp_arr_def shape: ', X_amp_arr_def.shape)\n",
    "    print('X_amp_arr_non_def shape: ', X_amp_arr_non_def.shape)\n",
    "    \n",
    "    print('Y_arr_def shape: ', Y_arr_def.shape)\n",
    "    print('Y_arr_non_def shape: ', Y_arr_non_def.shape)\n",
    "    print('||||||||||||||||||\\n')\n",
    "    print('||||||||||||||||||\\n')\n",
    "    \n",
    "    return (X_time_arr_def,X_time_arr_non_def),(X_amp_arr_def,X_amp_arr_non_def),(Y_arr_def,Y_arr_non_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.788822Z",
     "start_time": "2023-04-14T09:32:06.760838Z"
    }
   },
   "outputs": [],
   "source": [
    "# применить аугментации к данным\n",
    "# повернуть каждую картинку на 90 градусов 3 раза как пример\n",
    "# для увеличения кол-ва данных для обучения\n",
    "def augment_data(X_time_arr, X_amp_arr, Y_arr):\n",
    "    print('||||||||||||||||||')\n",
    "    print('Data augmentation')\n",
    "    \n",
    "    print('Orig X_time_arr shape: ', X_time_arr.shape)\n",
    "    print('Orig X_amp_arr shape: ', X_amp_arr.shape)\n",
    "    print('Orig Y_arr shape: ', Y_arr.shape)\n",
    "    \n",
    "    X_time_arr = np.concatenate([X_time_arr,\n",
    "                            np.rot90(X_time_arr,1,[1,2]),\n",
    "                            np.rot90(X_time_arr,2,[1,2]),\n",
    "                            np.rot90(X_time_arr,3,[1,2])],axis=0)\n",
    "\n",
    "    X_amp_arr = np.concatenate([X_amp_arr,\n",
    "                            np.rot90(X_amp_arr,1,[1,2]),\n",
    "                            np.rot90(X_amp_arr,2,[1,2]),\n",
    "                            np.rot90(X_amp_arr,3,[1,2])],axis=0)\n",
    "\n",
    "    Y_arr = np.concatenate([Y_arr,\n",
    "                            np.rot90(Y_arr,1,[1,2]),\n",
    "                            np.rot90(Y_arr,2,[1,2]),\n",
    "                            np.rot90(Y_arr,3,[1,2])],axis=0)\n",
    "    \n",
    "    X_time_arr = np.concatenate([X_time_arr,np.flip(X_time_arr,2)],axis=0)\n",
    "    X_amp_arr = np.concatenate([X_amp_arr,np.flip(X_amp_arr,2)],axis=0)\n",
    "    Y_arr = np.concatenate([Y_arr,np.flip(Y_arr,2)],axis=0)\n",
    "    \n",
    "    print('Result X_time_arr shape: ', X_time_arr.shape)\n",
    "    print('Result X_amp_arr shape: ', X_amp_arr.shape)\n",
    "    print('Result Y_arr shape: ', Y_arr.shape)\n",
    "    \n",
    "    print('||||||||||||||||||\\n')\n",
    "    return X_time_arr, X_amp_arr, Y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:06.819801Z",
     "start_time": "2023-04-14T09:32:06.800814Z"
    }
   },
   "outputs": [],
   "source": [
    "# датафрейм размера 112 на 400 при размере кропа в 10\n",
    "# преобразует в размер 120 на 400 (чтобы каждая сторона ровно\n",
    "# делилась на размер кропа)\n",
    "# новые строки добавляются за счет копирования старых\n",
    "def reshape_df_for_future_crops(df, crop_size):\n",
    "    \n",
    "    print('||||||||||||||||||')\n",
    "    print('Df reshaping for exact splitting with crop_size')\n",
    "    print('Original df size: ', df.shape)\n",
    "    print('Crop windows height/width: ', crop_size)\n",
    "    \n",
    "    if df.shape[0] % crop_size == 0:\n",
    "        return df\n",
    "    \n",
    "    new_rows = crop_size - (df.shape[0] % crop_size)\n",
    "    \n",
    "    df = pd.concat([df,df.iloc[-1:-new_rows-1:-1]],axis=0,ignore_index=True)\n",
    "    \n",
    "    print('New df shape: ', df.shape)\n",
    "    print('||||||||||||||||||\\n')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:28.477195Z",
     "start_time": "2023-04-14T09:32:06.823800Z"
    }
   },
   "outputs": [],
   "source": [
    "# загрузка данных из файлов\n",
    "X_dict = dict()\n",
    "Y_dict = dict()\n",
    "\n",
    "for i,x_data_path,y_data_path in zip(range(len(path_to_array_like_X_data)),\n",
    "                                     path_to_array_like_X_data, \n",
    "                                     path_to_Y_data):\n",
    "    \n",
    "    x_temp = get_array_like_X_df(x_data_path)\n",
    "    y_temp = get_Y_df(y_data_path)\n",
    "    \n",
    "    X_dict[f'run{i+1}'] = {'df': x_temp}\n",
    "    Y_dict[f'run{i+1}'] = {'df': y_temp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:28.509106Z",
     "start_time": "2023-04-14T09:32:28.477195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружены данные для X выборки из файлов:  dict_keys(['run1', 'run2'])\n",
      "Загружены данные для Y выборки из файлов:  dict_keys(['run1', 'run2'])\n"
     ]
    }
   ],
   "source": [
    "print('Загружены данные для X выборки из файлов: ', X_dict.keys())\n",
    "print('Загружены данные для Y выборки из файлов: ', Y_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:28.557073Z",
     "start_time": "2023-04-14T09:32:28.514099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||\n",
      "Df reshaping for exact splitting with crop_size\n",
      "Original df size:  (115, 400)\n",
      "Crop windows height/width:  10\n",
      "New df shape:  (120, 400)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Df reshaping for exact splitting with crop_size\n",
      "Original df size:  (115, 400)\n",
      "Crop windows height/width:  10\n",
      "New df shape:  (120, 400)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Df reshaping for exact splitting with crop_size\n",
      "Original df size:  (119, 400)\n",
      "Crop windows height/width:  10\n",
      "New df shape:  (120, 400)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Df reshaping for exact splitting with crop_size\n",
      "Original df size:  (119, 400)\n",
      "Crop windows height/width:  10\n",
      "New df shape:  (120, 400)\n",
      "||||||||||||||||||\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# добавление строк в датафреймы\n",
    "for key in X_dict.keys():\n",
    "    X_dict[key]['df'] = reshape_df_for_future_crops(X_dict[key]['df'], PREP_image_size)\n",
    "    Y_dict[key]['df'] = reshape_df_for_future_crops(Y_dict[key]['df'], PREP_image_size) \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:29.735359Z",
     "start_time": "2023-04-14T09:32:28.562070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||\n",
      "X df reshaping to 4D\n",
      "Original df size:  (120, 400)\n",
      "Crop windows height/width:  10\n",
      "New X_time shape:  (480, 10, 10, 32)\n",
      "New X_amp shape:  (480, 10, 10, 32)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Y df reshaping to 3D\n",
      "Original df size:  (120, 400)\n",
      "Crop windows height/width:  10\n",
      "New numpy shape:  (480, 10, 10, 1)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "X df reshaping to 4D\n",
      "Original df size:  (120, 400)\n",
      "Crop windows height/width:  10\n",
      "New X_time shape:  (480, 10, 10, 32)\n",
      "New X_amp shape:  (480, 10, 10, 32)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Y df reshaping to 3D\n",
      "Original df size:  (120, 400)\n",
      "Crop windows height/width:  10\n",
      "New numpy shape:  (480, 10, 10, 1)\n",
      "||||||||||||||||||\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# запишем в словарь numpy array полученные из df\n",
    "for key in X_dict.keys():\n",
    "    x_time_temp, x_amp_temp = reshape_X_df_to_image_like_numpy(X_dict[key]['df'], PREP_image_size)\n",
    "    \n",
    "    X_dict[key]['X_time_all'] = x_time_temp\n",
    "    X_dict[key]['X_amp_all'] = x_amp_temp\n",
    "    \n",
    "    y_temp = reshape_Y_df_to_image_like_numpy(Y_dict[key]['df'], PREP_image_size)\n",
    "    \n",
    "    Y_dict[key]['Y_all'] = y_temp \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:29.766737Z",
     "start_time": "2023-04-14T09:32:29.739753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X данные считаны для файлов:  dict_keys(['run1', 'run2'])\n",
      "Для файла run1 считаны такие данные:  dict_keys(['df', 'X_time_all', 'X_amp_all'])\n",
      "Для файла run2 считаны такие данные:  dict_keys(['df', 'X_time_all', 'X_amp_all'])\n",
      "\n",
      "Y данные считаны для файлов:  dict_keys(['run1', 'run2'])\n",
      "Для файла run1 считаны такие данные:  dict_keys(['df', 'Y_all'])\n",
      "Для файла run2 считаны такие данные:  dict_keys(['df', 'Y_all'])\n"
     ]
    }
   ],
   "source": [
    "print('X данные считаны для файлов: ',X_dict.keys())\n",
    "for key in X_dict.keys():\n",
    "    print('Для файла', key, 'считаны такие данные: ', X_dict[key].keys())\n",
    "    \n",
    "print('\\nY данные считаны для файлов: ',Y_dict.keys())\n",
    "for key in Y_dict.keys():\n",
    "    print('Для файла', key, 'считаны такие данные: ', Y_dict[key].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:29.955620Z",
     "start_time": "2023-04-14T09:32:29.774732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||\n",
      "Файл:  run1\n",
      "||||||||||||||||||\n",
      "Data preprocessing\n",
      "Orig X_time_arr shape:  (480, 10, 10, 32)\n",
      "Orig X_amp_arr shape:  (480, 10, 10, 32)\n",
      "Orig Y_arr shape:  (480, 10, 10, 1)\n",
      "||||||||||||||||||\n",
      "Data standartization\n",
      "X_time_max: 44.5\n",
      "X_amp_max: 62.992\n",
      "X_time_max after standartization: 1.0\n",
      "X_time_min after standartization: 0.0\n",
      "X_amp_max after standartization: 1.0\n",
      "X_amp_min after standartization: -0.983743967487935\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Data with and witout defects splitting\n",
      "||||||||||||||||||\n",
      "Defects nums calculating\n",
      "Для карт высотой и шириной в 10\n",
      "и общим кличеством: 480\n",
      "дефекты присутствуеют на 33 картах\n",
      "||||||||||||||||||\n",
      "\n",
      "X_time_arr_def shape:  (33, 10, 10, 32)\n",
      "X_time_arr_non_def shape:  (447, 10, 10, 32)\n",
      "X_amp_arr_def shape:  (33, 10, 10, 32)\n",
      "X_amp_arr_non_def shape:  (447, 10, 10, 32)\n",
      "Y_arr_def shape:  (33, 10, 10, 1)\n",
      "Y_arr_non_def shape:  (447, 10, 10, 1)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Файл:  run2\n",
      "||||||||||||||||||\n",
      "Data preprocessing\n",
      "Orig X_time_arr shape:  (480, 10, 10, 32)\n",
      "Orig X_amp_arr shape:  (480, 10, 10, 32)\n",
      "Orig Y_arr shape:  (480, 10, 10, 1)\n",
      "||||||||||||||||||\n",
      "Data standartization\n",
      "X_time_max: 44.4\n",
      "X_amp_max: 62.992\n",
      "X_time_max after standartization: 1.0\n",
      "X_time_min after standartization: 0.0\n",
      "X_amp_max after standartization: 1.0\n",
      "X_amp_min after standartization: -0.9919037338074677\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Data with and witout defects splitting\n",
      "||||||||||||||||||\n",
      "Defects nums calculating\n",
      "Для карт высотой и шириной в 10\n",
      "и общим кличеством: 480\n",
      "дефекты присутствуеют на 28 картах\n",
      "||||||||||||||||||\n",
      "\n",
      "X_time_arr_def shape:  (28, 10, 10, 32)\n",
      "X_time_arr_non_def shape:  (452, 10, 10, 32)\n",
      "X_amp_arr_def shape:  (28, 10, 10, 32)\n",
      "X_amp_arr_non_def shape:  (452, 10, 10, 32)\n",
      "Y_arr_def shape:  (28, 10, 10, 1)\n",
      "Y_arr_non_def shape:  (452, 10, 10, 1)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обработка данных\n",
    "for key in X_dict.keys():\n",
    "    print('||||||||||||||||||')\n",
    "    print('Файл: ', key)\n",
    "    \n",
    "    (X_time_def,X_time_non_def), \\\n",
    "    (X_amp_def,X_amp_non_def), \\\n",
    "    (Y_def,Y_non_def) = preprocess_data(X_dict[key]['X_time_all'], \n",
    "                                        X_dict[key]['X_amp_all'], \n",
    "                                        Y_dict[key]['Y_all'],\n",
    "                                        PREP_image_size)\n",
    "    \n",
    "    X_dict[key]['X_time_def'] = X_time_def\n",
    "    X_dict[key]['X_time_non_def'] = X_time_non_def\n",
    "    \n",
    "    X_dict[key]['X_amp_def'] = X_amp_def\n",
    "    X_dict[key]['X_amp_non_def'] = X_amp_non_def\n",
    "    \n",
    "    Y_dict[key]['Y_def'] = Y_def\n",
    "    Y_dict[key]['Y_non_def'] = Y_non_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:30.002588Z",
     "start_time": "2023-04-14T09:32:29.960615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X данные считаны для файлов:  dict_keys(['run1', 'run2'])\n",
      "Для файла run1 считаны такие данные:  dict_keys(['df', 'X_time_all', 'X_amp_all', 'X_time_def', 'X_time_non_def', 'X_amp_def', 'X_amp_non_def'])\n",
      "Для файла run2 считаны такие данные:  dict_keys(['df', 'X_time_all', 'X_amp_all', 'X_time_def', 'X_time_non_def', 'X_amp_def', 'X_amp_non_def'])\n",
      "\n",
      "Y данные считаны для файлов:  dict_keys(['run1', 'run2'])\n",
      "Для файла run1 считаны такие данные:  dict_keys(['df', 'Y_all', 'Y_def', 'Y_non_def'])\n",
      "Для файла run2 считаны такие данные:  dict_keys(['df', 'Y_all', 'Y_def', 'Y_non_def'])\n"
     ]
    }
   ],
   "source": [
    "print('X данные считаны для файлов: ',X_dict.keys())\n",
    "for key in X_dict.keys():\n",
    "    print('Для файла', key, 'считаны такие данные: ', X_dict[key].keys())\n",
    "    \n",
    "print('\\nY данные считаны для файлов: ',Y_dict.keys())\n",
    "for key in Y_dict.keys():\n",
    "    print('Для файла', key, 'считаны такие данные: ', Y_dict[key].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:30.114520Z",
     "start_time": "2023-04-14T09:32:30.008586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||\n",
      "Data augmentation\n",
      "Orig X_time_arr shape:  (33, 10, 10, 32)\n",
      "Orig X_amp_arr shape:  (33, 10, 10, 32)\n",
      "Orig Y_arr shape:  (33, 10, 10, 1)\n",
      "Result X_time_arr shape:  (264, 10, 10, 32)\n",
      "Result X_amp_arr shape:  (264, 10, 10, 32)\n",
      "Result Y_arr shape:  (264, 10, 10, 1)\n",
      "||||||||||||||||||\n",
      "\n",
      "||||||||||||||||||\n",
      "Data augmentation\n",
      "Orig X_time_arr shape:  (28, 10, 10, 32)\n",
      "Orig X_amp_arr shape:  (28, 10, 10, 32)\n",
      "Orig Y_arr shape:  (28, 10, 10, 1)\n",
      "Result X_time_arr shape:  (224, 10, 10, 32)\n",
      "Result X_amp_arr shape:  (224, 10, 10, 32)\n",
      "Result Y_arr shape:  (224, 10, 10, 1)\n",
      "||||||||||||||||||\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# аугментация данных\n",
    "X_time_train_1, X_amp_train_1, Y_train_1 = augment_data(X_dict['run1']['X_time_def'],\n",
    "                                                        X_dict['run1']['X_amp_def'],\n",
    "                                                        Y_dict['run1']['Y_def'])\n",
    "\n",
    "X_time_train_2, X_amp_train_2, Y_train_2 = augment_data(X_dict['run2']['X_time_def'],\n",
    "                                                        X_dict['run2']['X_amp_def'],\n",
    "                                                        Y_dict['run2']['Y_def'])\n",
    "\n",
    "train_data_percent = 0.8\n",
    "\n",
    "# возьмем половину данных из файлов run1 и run2, соеденим\n",
    "# получим тренировочную выборку\n",
    "X_time_train = np.concatenate([X_time_train_1[:int(X_time_train_1.shape[0]*train_data_percent)],\n",
    "                               X_time_train_2[:int(X_time_train_2.shape[0]*train_data_percent)]],axis=0)\n",
    "\n",
    "X_amp_train = np.concatenate([X_amp_train_1[:int(X_amp_train_1.shape[0]*train_data_percent)],\n",
    "                              X_amp_train_2[:int(X_amp_train_2.shape[0]*train_data_percent)]],axis=0)\n",
    "\n",
    "Y_train = np.concatenate([Y_train_1[:int(Y_train_1.shape[0]*train_data_percent)],\n",
    "                          Y_train_2[:int(Y_train_2.shape[0]*train_data_percent)]],axis=0)\n",
    "\n",
    "\n",
    "# возьмем вторую половину данных из файлов run1 и run2, соеденим\n",
    "# получим тестовую выборку\n",
    "\n",
    "X_time_test = np.concatenate([X_time_train_1[int(X_time_train_1.shape[0]*train_data_percent):],\n",
    "                              X_time_train_2[int(X_time_train_2.shape[0]*train_data_percent):]],axis=0)\n",
    "\n",
    "X_amp_test = np.concatenate([X_amp_train_1[int(X_amp_train_1.shape[0]*train_data_percent):],\n",
    "                             X_amp_train_2[int(X_amp_train_2.shape[0]*train_data_percent):]],axis=0)\n",
    "\n",
    "Y_test = np.concatenate([Y_train_1[int(Y_train_1.shape[0]*train_data_percent):],\n",
    "                         Y_train_2[int(Y_train_2.shape[0]*train_data_percent):]],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:32:30.162490Z",
     "start_time": "2023-04-14T09:32:30.121515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_time_train.shape:  (390, 10, 10, 32)\n",
      "X_amp_train.shape (390, 10, 10, 32)\n",
      "Y_train.shape (390, 10, 10, 1)\n",
      "X_time_test.shape (98, 10, 10, 32)\n",
      "X_amp_test.shape (98, 10, 10, 32)\n",
      "Y_test.shape (98, 10, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_time_train.shape: ', X_time_train.shape)\n",
    "print('X_amp_train.shape',X_amp_train.shape)\n",
    "print('Y_train.shape',Y_train.shape)\n",
    "\n",
    "print('X_time_test.shape',X_time_test.shape)\n",
    "print('X_amp_test.shape',X_amp_test.shape)\n",
    "print('Y_test.shape',Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:12:33.027049Z",
     "start_time": "2023-04-14T10:12:33.007062Z"
    }
   },
   "outputs": [],
   "source": [
    "# всякие константы для последующей работы\n",
    "\n",
    "#///////////////////////////////// для компиляции \n",
    "\n",
    "CMP_learning_rate = 0.0001 #0.04 # шаг сходимости back propogation\n",
    "CMP_solver = keras.optimizers.Adam(CMP_learning_rate) # оптимизатор\n",
    "#CMP_solver = keras.optimizers.SGD(CMP_learning_rate) # оптимизатор\n",
    "CMP_loss_func = 'binary_crossentropy'#'mean_squared_error'# функция потерь\n",
    "#///////////////////////////////// для колбэков\n",
    "\n",
    "    # для Early_stopping\n",
    "ES_patience = 15 # кол-во эпох без улучшений\n",
    "ES_min_delta = 0.00005 # минимальное улучшение параметра за cur_patience\n",
    "ES_monitor_parametr =  'loss' # отслеживаемый параметр \n",
    "ES_save_best_weights = True # сохранять ли веса нейронки с лучшими результатами\n",
    "    \n",
    "    # для ReduceLROnPlateau\n",
    "RLPOP_monitor_parametr = 'val_loss'  # отслеживаемый параметр \n",
    "RLPOP_factor = 0.2 # множитель для расчета нового шага сходимости (new_learning_rate = old_learning_rate*RLPOP_factor)\n",
    "RLPOP_patience = 5 # кол-во эпох без улучшений\n",
    "RLPOP_verbose = 1 # выводить ли прогресс изменения шага сходимости в его процессее\n",
    "RLPOP_mode = 'auto' # выбирает, уменьшать шаг сходимости при росте величины или при её уменьшении\n",
    "RLPOP_min_delta = 0.0001 # порог изменения отслеживаемого значения\n",
    "RLPOP_cooldown = 0 # количество эпох до возобновления работы после изменения шага сходимости\n",
    "RLPOP_min_lr = 0 # минимальное значение шага сходимости\n",
    "\n",
    "    # для CallbackList\n",
    "CBL_add_history = True # вызывать ли колбэк History (если он не был довавлен вручную)\n",
    "CBL_add_progbar = True # вызывать ли колбэк ProgbarLogger (если он не был довавлен вручную)\n",
    "    \n",
    "#///////////////////////////////// для тренировки\n",
    "\n",
    "FIT_batch_size = 8 # размер bach при обучении/тестировании1\n",
    "FIT_shuffle = True # перемешивать ли данные\n",
    "FIT_verbose = True # выводить ли прогресс обучения в его процессее\n",
    "FIT_epochs = 20 # количество эпох обучения\n",
    "FIT_validation_split = 0.20 #0.20 # процент валидационных данных, отсекаемых из тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:12:34.257777Z",
     "start_time": "2023-04-14T10:12:33.558757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 10, 10, 32)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 10, 10, 32)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 10, 10, 128)  36992       input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 10, 10, 128)  36992       input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 10, 10, 128)  147584      conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 10, 10, 128)  147584      conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling2D) (None, 5, 5, 128)    0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling2D) (None, 5, 5, 128)    0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 5, 5, 128)    0           max_pooling2d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 5, 5, 128)    0           max_pooling2d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 5, 5, 512)    590336      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 5, 5, 512)    590336      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 5, 5, 512)    2359808     conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 5, 5, 512)    2359808     conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 5, 5, 512)    2048        conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 5, 5, 512)    2048        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 12800)        0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 12800)        0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 25600)        0           flatten_20[0][0]                 \n",
      "                                                                 flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 8, 8, 400)    0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 8, 8, 200)    720200      reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 8, 8, 200)    360200      conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D) (None, 4, 4, 200)    0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 4, 4, 200)    0           max_pooling2d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 4, 4, 100)    180100      dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 4, 4, 100)    90100       conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 2, 2, 100)    0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 2, 2, 100)    0           max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 2, 2, 50)     45050       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 2, 2, 50)     22550       conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 2, 2, 25)     11275       conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 2, 2, 25)     5650        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 10, 10, 1)    0           conv2d_155[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,708,661\n",
      "Trainable params: 7,706,613\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_time = Input((10,10,32))\n",
    "t = Conv2D(128, (3,3), padding='same', activation='relu', input_shape=(28,28,1))(input_time)\n",
    "t = Conv2D(128, (3,3), padding='same', activation='relu')(t)\n",
    "t = MaxPooling2D((2,2), strides=2)(t)\n",
    "t = Dropout(0.5)(t)\n",
    "t = Conv2D(512, (3,3), padding='same', activation='relu')(t)\n",
    "t = Conv2D(512, (3,3), padding='same', activation='relu')(t)\n",
    "t = BatchNormalization()(t)\n",
    "output_time = Flatten()(t)\n",
    "\n",
    "input_amp = Input((10,10,32))\n",
    "a = Conv2D(128, (3,3), padding='same', activation='linear', input_shape=(28,28,1))(input_amp)\n",
    "a = Conv2D(128, (3,3), padding='same', activation='linear')(a)\n",
    "a = MaxPooling2D((2,2), strides=2)(a)\n",
    "a = Dropout(0.5)(a)\n",
    "a = Conv2D(512, (3,3), padding='same', activation='linear')(a)\n",
    "a = Conv2D(512, (3,3), padding='same', activation='linear')(a)\n",
    "a = BatchNormalization()(a)\n",
    "output_amp = Flatten()(a)\n",
    "\n",
    "at = concatenate([output_time,output_amp])\n",
    "at = Reshape((8,8,400))(at)\n",
    "at = Conv2D(200, (3,3), padding='same', activation='linear')(at)\n",
    "at = Conv2D(200, (3,3), padding='same', activation='linear')(at)\n",
    "at = MaxPooling2D((2,2), strides=2)(at)\n",
    "at = Dropout(0.5)(at)\n",
    "at = Conv2D(100, (3,3), padding='same', activation='linear')(at)\n",
    "at = Conv2D(100, (3,3), padding='same', activation='linear')(at)\n",
    "at = MaxPooling2D((2,2), strides=2)(at)\n",
    "at = Dropout(0.5)(at)\n",
    "at = Conv2D(50, (3,3), padding='same', activation='relu')(at)\n",
    "at = Conv2D(50, (3,3), padding='same', activation='relu')(at)\n",
    "at = Conv2D(25, (3,3), padding='same', activation='sigmoid')(at)\n",
    "at = Conv2D(25, (3,3), padding='same', activation='sigmoid')(at)\n",
    "\n",
    "\n",
    "output = Reshape((10,10,1))(at)\n",
    "\n",
    "model = keras.Model([input_time,input_amp], output, name='model')\n",
    "model.compile(optimizer=CMP_solver, loss=CMP_loss_func)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:12:38.583110Z",
     "start_time": "2023-04-14T10:12:38.566118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Создание и настройка колбэков\n",
    "callback_list = [] # массив колбэков до подачи в колбек \"callbacklist\"\n",
    "\n",
    "temp = keras.callbacks.EarlyStopping(\n",
    "            monitor = ES_monitor_parametr, \n",
    "            min_delta = ES_min_delta, \n",
    "            patience = ES_patience,\n",
    "            restore_best_weights = ES_save_best_weights\n",
    "            )\n",
    "callback_list.append(temp)\n",
    "\n",
    "temp = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = RLPOP_monitor_parametr, \n",
    "            factor = RLPOP_factor, \n",
    "            patience = RLPOP_patience, \n",
    "            verbose = RLPOP_verbose,\n",
    "            mode = RLPOP_mode, \n",
    "            min_delta = RLPOP_min_delta, \n",
    "            cooldown = RLPOP_cooldown, \n",
    "            min_lr = RLPOP_min_lr\n",
    "            )\n",
    "callback_list.append(temp)\n",
    "\n",
    "FIT_callback_list = keras.callbacks.CallbackList(\n",
    "            callbacks = callback_list, \n",
    "            add_history = CBL_add_history, \n",
    "            add_progbar = CBL_add_progbar, \n",
    "            model = model\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:12:59.320110Z",
     "start_time": "2023-04-14T10:12:39.159214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25/Unknown - 15s 603ms/step - loss: 0.6723"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2936/4143390375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit([X_time_train,X_amp_train],\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFIT_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFIT_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFIT_verbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\network\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([X_time_train,X_amp_train],\n",
    "                    Y_train,\n",
    "                    batch_size = FIT_batch_size, \n",
    "                    epochs = FIT_epochs, \n",
    "                    verbose = FIT_verbose, \n",
    "                    validation_split = FIT_validation_split, \n",
    "                    shuffle = FIT_shuffle, \n",
    "                    callbacks = FIT_callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:12:59.326106Z",
     "start_time": "2023-04-14T10:12:59.326106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Вывод графика изменения ошибки\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(6)\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss',  linewidth=1.5, color='blue')\n",
    "plt.plot(history.history['val_loss'], linestyle = '--', label='val_loss',  linewidth=3, color='red')\n",
    "\n",
    "ax.set_title('График ошибки во время обучения', fontsize=20)\n",
    "ax.set_ylabel('Ошибка', fontsize=15)\n",
    "ax.set_xlabel('Эпохи', fontsize=15)\n",
    "\n",
    "#  Устанавливаем форматирование делений:\n",
    "ax.xaxis.set_tick_params(which = 'major', labelsize = 14)\n",
    "ax.yaxis.set_tick_params(which = 'major', labelsize = 14)\n",
    "\n",
    "ax.minorticks_on()\n",
    "ax.grid(which='major', color = 'k', alpha = 0.6)\n",
    "ax.grid(which='minor', color = 'gray', linestyle = ':')\n",
    "\n",
    "ax.legend(fontsize = 15, facecolor = \"white\", loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:12:59.329104Z",
     "start_time": "2023-04-14T10:12:59.329104Z"
    }
   },
   "outputs": [],
   "source": [
    "# тест модели\n",
    "model.evaluate([X_time_test,X_amp_test], Y_test, batch_size = FIT_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "res = model.predict([X_time_def,X_amp_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(40,2)\n",
    "\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(80)\n",
    "\n",
    "for i,iax in zip(range(40),ax):\n",
    "    \n",
    "    iax[0].imshow(res[i])\n",
    "\n",
    "    iax[0].set_xlabel('Номер датчика', fontsize=10) \n",
    "    iax[0].set_ylabel('Номер измерения', fontsize=10) \n",
    "    iax[0].set_title('Результат модели', fontsize=10) \n",
    "\n",
    "    iax[1].imshow(Y_res_def[i])\n",
    "\n",
    "    iax[1].set_xlabel('Желаемый результат', fontsize=10) \n",
    "    iax[1].set_ylabel('Номер измерения', fontsize=10) \n",
    "    iax[1].set_title('Карта дефектов', fontsize=10) \n",
    "\n",
    "     \n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.1, hspace=0.8)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
